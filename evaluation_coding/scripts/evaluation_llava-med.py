import re
import json
import torch
import string
import numpy as np
import traceback  # æ·»åŠ tracebackæ¨¡å—
from tqdm import tqdm
from transformers import LlavaForConditionalGeneration, AutoProcessor
from PIL import Image
import os

# å®šä¹‰é¢œè‰²çš„ANSIä»£ç 
RED = '\033[91m'
GREEN = '\033[92m'
YELLOW = '\033[93m'
RESET = '\033[0m'

# æ¨¡å‹è·¯å¾„
model_path = "/cluster/home/user1/YuanWenzhen/workspace/Visual-RFT/Visual-ARFT/shared/mllm_ckpts/llava-med-v1.5-mistral-7b-hf"

# åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
print("åŠ è½½æ¨¡å‹...")
try:
    model = LlavaForConditionalGeneration.from_pretrained(
        model_path,
        torch_dtype=torch.bfloat16,
        device_map="cuda:3",
        trust_remote_code=True
    )
    processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)
    print("âœ… æœ¬åœ°æ¨¡å‹åŠ è½½æˆåŠŸ")
except Exception as e:
    print(f"æœ¬åœ°åŠ è½½å¤±è´¥: {e}")
    print("å°è¯•ä»HuggingFaceåŠ è½½...")
    model_path = "chaoyinshe/llava-med-v1.5-mistral-7b-hf"
    model = LlavaForConditionalGeneration.from_pretrained(
        model_path,
        torch_dtype=torch.bfloat16,
        device_map="cuda:3",
        trust_remote_code=True
    )
    processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)
    print("âœ… HuggingFaceæ¨¡å‹åŠ è½½æˆåŠŸ")

# æ•°æ®è·¯å¾„
noise_name = 'BC'
input_data_path = f'/cluster/home/user1/YuanWenzhen/workspace/Visual-RFT/Visual-ARFT/data/MAT-Benchmark/all_noise_100_test/{noise_name}/data.json'
folder_name = os.path.basename(os.path.dirname(input_data_path))
output_filename = f"llava-med-v1.5-mistral-7b-hf_result/{folder_name}_result.json"
os.makedirs("llava-med-v1.5-mistral-7b-hf_result", exist_ok=True)

# åŠ è½½æ•°æ®
with open(input_data_path, 'r') as file:
    wikimultihopqa = json.load(file)
print(f"æ•°æ®æ ·æœ¬æ•°: {len(wikimultihopqa)}")

combine_results = []
for item in tqdm(wikimultihopqa[:]):
    try:
        print(f"ğŸ” å¤„ç†æ•°æ®: {item}")  # æ‰“å°å®Œæ•´çš„itemæ•°æ®
        
        # ğŸ”§ ä¿®å¤ï¼šå®‰å…¨åœ°è·å–å›¾åƒè·¯å¾„
        print(f"ğŸ” item['type']: {item['type']}, type: {type(item['type'])}")
        print(f"ğŸ” item['type'][0]: {item['type'][0]}")
        
        if item['type'][0] == 'crop':
            image_path = item['ori_image_path']
            print(f"ğŸ” ä½¿ç”¨ ori_image_path: {image_path}, type: {type(image_path)}")
        else:
            image_path = item['processed_image_path']
            print(f"ğŸ” ä½¿ç”¨ processed_image_path: {image_path}, type: {type(image_path)}")
        
        # ğŸ”§ å¤„ç†è·¯å¾„å¯èƒ½æ˜¯åˆ—è¡¨çš„æƒ…å†µ
        if isinstance(image_path, list):
            print(f"ğŸ” image_path æ˜¯åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ ")
            image_path = image_path[0] if image_path else ""
        image_path = str(image_path)  # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²
        print(f"ğŸ” æœ€ç»ˆ image_path: {image_path}")
        
        base_path = f'/cluster/home/user1/YuanWenzhen/workspace/Visual-RFT/Visual-ARFT/data/MAT-Benchmark/all_noise_100_test/{noise_name}/images/'
        print(f"ğŸ” base_path: {base_path}")
        print(f"ğŸ” å‡†å¤‡æ‹¼æ¥è·¯å¾„...")
        
        input_image_path = base_path + image_path
        print(f"ğŸ” æ‹¼æ¥åçš„è·¯å¾„: {input_image_path}")
        
        if not os.path.exists(input_image_path):
            pred_answer = "Image not found"
            combine_results.append({'pred_answer': pred_answer, 'gt': item['answer'], 'query': item['question']})
            continue

        # åŠ è½½å›¾åƒ
        image = Image.open(input_image_path).convert("RGB")
        
        # ğŸ”§ å¤„ç†é—®é¢˜å¯èƒ½æ˜¯åˆ—è¡¨çš„æƒ…å†µ
        query = item['question']
        print(f"ğŸ” query: {query}, type: {type(query)}")
        if isinstance(query, list):
            query = query[0] if query else ""
        query = str(query)
        
        input_text = query + '\n' + "Answer the question directly. The answer should be very brief."
        print(RED + input_text + RESET)
        
        # ğŸ”§ ä¿®å¤ï¼šå¤„ç†ç­”æ¡ˆå¯èƒ½æ˜¯åˆ—è¡¨çš„æƒ…å†µ
        answer = item['answer']
        print(f"ğŸ” answer: {answer}, type: {type(answer)}")
        if isinstance(answer, list):
            answer_str = ', '.join(str(ans) for ans in answer)  # å°†åˆ—è¡¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        else:
            answer_str = str(answer)  # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²
        print(GREEN + answer_str + RESET)
        
        # ğŸ”§ ä½¿ç”¨å®˜æ–¹ç¤ºä¾‹çš„æ ¼å¼
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image"},
                    {"type": "text", "text": input_text}
                ]
            }
        ]
        
        # ğŸ”§ ä½¿ç”¨å®˜æ–¹çš„apply_chat_templateæ–¹æ³•
        prompt = processor.tokenizer.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )
        
        # ğŸ”§ æŒ‰ç…§å®˜æ–¹ç¤ºä¾‹å¤„ç†è¾“å…¥
        inputs = processor(
            images=[image], text=prompt, return_tensors="pt"
        ).to(model.device, torch.bfloat16)
        
        # ğŸ”§ ä½¿ç”¨å®˜æ–¹çš„æ¨ç†æ–¹å¼
        with torch.inference_mode():
            output_ids = model.generate(
                **inputs,
                max_new_tokens=256,
                do_sample=False,
                pad_token_id=processor.tokenizer.eos_token_id,
                eos_token_id=processor.tokenizer.eos_token_id
            )
        
        # ğŸ”§ ä½¿ç”¨å®˜æ–¹çš„è§£ç æ–¹å¼
        result = processor.decode(output_ids[0], skip_special_tokens=True)
        
        # æå–å›ç­”éƒ¨åˆ† - ç§»é™¤è¾“å…¥çš„promptéƒ¨åˆ†
        if prompt in result:
            pred_answer = result.replace(prompt, "").strip()
        elif "assistant" in result.lower():
            # æŸ¥æ‰¾assistantåçš„å†…å®¹
            parts = result.lower().split("assistant")
            if len(parts) > 1:
                pred_answer = result[result.lower().find("assistant") + len("assistant"):].strip()
            else:
                pred_answer = result.strip()
        else:
            pred_answer = result.strip()
        
        # æ¸…ç†å›ç­”å¼€å¤´çš„å†’å·æˆ–å…¶ä»–ç¬¦å·
        if pred_answer.startswith(":") or pred_answer.startswith("ï¼š"):
            pred_answer = pred_answer[1:].strip()
        
        print(YELLOW + pred_answer + RESET)

    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        print(f"é”™è¯¯è¯¦æƒ…: {type(e).__name__}: {str(e)}")
        print(f"å®Œæ•´é”™è¯¯è¿½è¸ª:")
        traceback.print_exc()  # æ‰“å°å®Œæ•´çš„é”™è¯¯è¿½è¸ª
        print(f"é—®é¢˜æ•°æ®: {item}")  # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        pred_answer = "Error in processing"
    
    combine_results.append(
        {'pred_answer': pred_answer, 'gt': item['answer'], 'query': item['question']}
    )

# ä¿å­˜ç»“æœ
with open(output_filename, "w", encoding="utf-8") as f:
    json.dump(combine_results, f, ensure_ascii=False, indent=4)
print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_filename}")
print(f"ğŸ“Š æ€»å…±å¤„ç†äº† {len(combine_results)} ä¸ªæ ·æœ¬")